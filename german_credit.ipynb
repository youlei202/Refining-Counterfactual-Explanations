{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To prevent automatic figure display when execution of the cell ends\n",
    "%config InlineBackend.close_figures=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from models.mlp import BlackBoxModel\n",
    "from models.rbf import RBFNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display,clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "df_ = pd.read_csv(os.path.join(data_path, 'german_credit_data.csv'))\n",
    "df = df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'Risk'\n",
    "target = df[target_name].replace({'good': 0, 'bad': 1})\n",
    "\n",
    "df[target_name] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Job  Housing  Saving accounts  Checking account  Credit amount  \\\n",
       "0   67    1    2        1                0                 1           1169   \n",
       "1   22    0    2        1                1                 2           5951   \n",
       "2   49    1    1        1                1                 0           2096   \n",
       "3   45    1    2        0                1                 1           7882   \n",
       "4   53    1    2        0                1                 1           4870   \n",
       "\n",
       "   Duration  Purpose  Risk  \n",
       "0         6        5     0  \n",
       "1        48        5     1  \n",
       "2        12        3     0  \n",
       "3        42        4     0  \n",
       "4        24        1     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_mappings = {}\n",
    "\n",
    "\n",
    "# Convert categorical columns to numerical representations using label encoding\n",
    "for column in df.columns:\n",
    "    if column is not target_name and df[column].dtype == 'object':\n",
    "        # Handle missing values by filling with a placeholder and then encoding\n",
    "        df[column] = df[column].fillna('Unknown')\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "        label_mappings[column] = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "\n",
    "\n",
    "# For columns with NaN values that are numerical, we will impute them with the median of the column\n",
    "for column in df.columns:\n",
    "    if df[column].isna().any():\n",
    "        median_val = df[column].median()\n",
    "        df[column].fillna(median_val, inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Age', \n",
    "    'Sex', \n",
    "    'Job', \n",
    "    'Housing', \n",
    "    'Saving accounts', \n",
    "    'Checking account',\n",
    "    'Credit amount', \n",
    "    'Duration', \n",
    "    'Purpose', \n",
    "]\n",
    "\n",
    "df_X = df[features].copy()\n",
    "df_y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassifier:\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)[:,0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "\n",
    "np.random.seed(seed)  # for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=seed)\n",
    "\n",
    "df_train = X_train.copy()\n",
    "df_test = X_test.copy()\n",
    "\n",
    "std = X_train.std()\n",
    "mean = X_train.mean()\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).view(-1, 1)\n",
    "\n",
    "model = CustomClassifier(model=AdaBoostClassifier())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# # Initialize the model, loss function, and optimizer\n",
    "# # model = RBFNet(input_dim=X_train.shape[1], hidden_dim=X_train.shape[1])\n",
    "# model = BlackBoxModel(input_dim=X_train.shape[1])\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 300\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Forward pass\n",
    "#     outputs = model(X_train_tensor)\n",
    "#     loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "#     # Backward pass and optimization\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # Evaluate on test set\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     test_outputs = model(X_test_tensor)\n",
    "#     test_loss = criterion(test_outputs, y_test_tensor)\n",
    "\n",
    "#     # Convert outputs to binary using 0.5 as threshold\n",
    "#     y_pred_tensor = (test_outputs > 0.5).float()\n",
    "#     correct_predictions = (y_pred_tensor == y_test_tensor).float().sum()\n",
    "#     accuracy = correct_predictions / y_test_tensor.shape[0]\n",
    "# test_accuracy = accuracy.item()\n",
    "\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainers import pshap, dce\n",
    "import dice_ml\n",
    "import shap\n",
    "import ot\n",
    "from utils.benchmarking import *\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:57<00:00,  4.75s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec73b6375f84cb7b885a706da51692a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58487275e-04,  1.09952111e-03,  1.73801825e-17,  6.76587208e-04,\n",
      "       -9.83008587e-04,  8.16831533e-03,  5.61672219e-03,  2.27123706e-03,\n",
      "       -3.42023259e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58684037e-04,  1.09975346e-03, -4.36208061e-18,  6.76728973e-04,\n",
      "       -9.83268927e-04,  8.16982552e-03,  9.22956432e-04, -4.39535145e-04,\n",
      "       -3.42114236e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 7.46202405e-03,  1.09982359e-03, -2.90936973e-17, -2.00542690e-03,\n",
      "       -9.83344782e-04, -1.24241986e-03,  2.24934921e-03, -1.47093235e-03,\n",
      "       -3.42128708e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58414068e-04,  1.09945622e-03, -7.02018663e-17, -8.29164331e-04,\n",
      "        2.70514972e-03,  8.16798658e-03, -3.40612588e-03,  7.31427314e-03,\n",
      "        1.45734466e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58779840e-04, -1.39968204e-03,  5.28223637e-18,  6.76789997e-04,\n",
      "       -9.83354041e-04,  7.51333714e-04,  2.94941268e-03,  2.27189782e-03,\n",
      "        1.45783262e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 7.45943294e-03,  1.09936620e-03, -7.07441339e-17, -8.29058568e-04,\n",
      "        2.70489010e-03,  8.16734241e-03,  2.24929662e-03, -4.39352875e-04,\n",
      "       -3.41981591e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18440059e-03,  1.09987224e-03, -5.54149254e-17,  6.76804579e-04,\n",
      "       -9.83389559e-04,  7.51350990e-04,  2.94923743e-03, -4.39565836e-04,\n",
      "       -3.42145301e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.47043415e-03,  1.09985602e-03, -4.17208935e-17,  6.76795312e-04,\n",
      "       -9.83347601e-04, -1.24239432e-03,  5.61751131e-03,  2.27189511e-03,\n",
      "       -3.42129305e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18436573e-03, -1.39968155e-03, -9.22709255e-17,  6.76801302e-04,\n",
      "       -9.83370206e-04,  7.51376286e-04,  5.61738284e-03, -4.39543390e-04,\n",
      "       -3.42135196e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58619059e-04, -1.39947092e-03,  4.19260359e-17, -8.29304481e-04,\n",
      "        2.70561850e-03,  8.16936681e-03,  1.39700204e-03,  2.27156207e-03,\n",
      "       -3.42086920e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58539707e-04,  1.09958272e-03, -4.39248069e-18,  6.76626805e-04,\n",
      "        1.23880955e-03,  8.16871341e-03,  5.61691907e-03, -1.47055752e-03,\n",
      "       -3.42042057e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18415236e-03,  1.09966642e-03, -6.72662825e-17,  6.76678049e-04,\n",
      "       -9.83155517e-04,  8.16922892e-03,  5.61716832e-03, -1.47068029e-03,\n",
      "        1.45758438e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18430591e-03,  1.09978984e-03, -4.42870320e-17,  6.76753888e-04,\n",
      "        4.02093766e-03,  7.51292870e-04,  2.94942513e-03,  2.27178237e-03,\n",
      "       -3.42113769e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58617521e-04, -1.39949251e-03, -4.45099083e-17,  6.76682523e-04,\n",
      "        2.70564084e-03,  8.16940808e-03, -4.51058309e-04,  2.27157224e-03,\n",
      "       -3.42093727e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18420154e-03, -1.39948107e-03,  1.84142512e-17,  6.76713484e-04,\n",
      "       -9.83210451e-04,  8.42557029e-03,  7.00260132e-03, -1.47074991e-03,\n",
      "       -3.42086444e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18408407e-03,  1.09958224e-03, -6.82222934e-17,  6.76623378e-04,\n",
      "       -9.83080276e-04,  8.16874380e-03,  3.06986009e-03,  3.56015636e-03,\n",
      "        1.45748436e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18435904e-03, -1.39967493e-03, -8.17758964e-17,  6.76798954e-04,\n",
      "       -9.83362261e-04, -1.24240570e-03,  5.61739887e-03,  2.27190428e-03,\n",
      "       -3.42133024e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58667882e-04, -1.39949284e-03,  1.90227842e-17,  6.76712245e-04,\n",
      "       -9.83215129e-04,  8.16957178e-03,  5.61732436e-03, -1.47076150e-03,\n",
      "       -3.42089614e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58415564e-04,  1.09944052e-03, -7.95566540e-17,  6.76537745e-04,\n",
      "       -9.82929902e-04,  8.16778873e-03,  5.61642909e-03,  2.27107556e-03,\n",
      "        1.45729203e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 7.45105482e-03,  1.09815398e-03, -5.75214799e-17,  6.75758262e-04,\n",
      "       -9.81626735e-04, -1.24004820e-03,  2.65270518e-02, -4.38667233e-04,\n",
      "       -3.41516668e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58412793e-04,  1.09944047e-03, -7.00599509e-17,  6.76539676e-04,\n",
      "        2.70503245e-03,  8.16778741e-03,  5.62974685e-03, -1.47035685e-03,\n",
      "        1.45729266e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.47000119e-03,  1.09951473e-03, -7.06229219e-17,  6.76583083e-04,\n",
      "        4.02002292e-03,  8.16830633e-03,  3.06974692e-03,  2.27123162e-03,\n",
      "       -3.42027979e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58669795e-04,  1.09972489e-03, -6.51591116e-18, -2.00519540e-03,\n",
      "       -9.83217968e-04,  8.16958023e-03,  5.61732573e-03, -1.47076386e-03,\n",
      "       -3.42090517e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58501992e-04,  1.09954476e-03,  2.83886918e-17,  6.76600960e-04,\n",
      "        1.23878197e-03,  8.16851782e-03,  2.94922633e-03,  2.27129358e-03,\n",
      "       -3.42038472e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58681855e-04,  1.09974856e-03,  9.90759345e-18,  6.76726912e-04,\n",
      "       -9.83257563e-04,  8.16977898e-03,  2.24956276e-03, -1.47083546e-03,\n",
      "       -3.42108244e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18384199e-03,  1.09938435e-03,  2.12384392e-17, -8.29049746e-04,\n",
      "        4.01954357e-03,  8.16740324e-03,  5.62952759e-03,  3.55953231e-03,\n",
      "       -3.41978314e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58487275e-04,  1.09952111e-03,  1.73801825e-17,  6.76587208e-04,\n",
      "       -9.83008587e-04,  8.16831533e-03,  5.61672219e-03,  2.27123706e-03,\n",
      "       -3.42023259e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18422432e-03,  1.09967958e-03, -6.53450915e-17,  6.76681789e-04,\n",
      "       -9.83195641e-04,  8.16939132e-03, -1.97741641e-04,  3.56047267e-03,\n",
      "        1.45762195e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18424156e-03, -1.39952596e-03,  5.45614036e-17,  6.76727502e-04,\n",
      "       -9.83240508e-04,  8.16971074e-03,  5.61737328e-03, -4.39499621e-04,\n",
      "       -3.42098683e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58538994e-04,  1.09958014e-03, -6.54752346e-18, -2.00492506e-03,\n",
      "        1.23881407e-03,  8.16871722e-03,  4.56268330e-03,  2.27136191e-03,\n",
      "       -3.42045645e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18416716e-03,  1.09968034e-03, -6.76202229e-17,  6.76686085e-04,\n",
      "       -9.83169114e-04,  8.42534682e-03,  5.63055636e-03, -4.39469867e-04,\n",
      "       -3.42075629e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58552194e-04,  1.09959615e-03,  1.63959932e-17,  6.76634787e-04,\n",
      "       -9.83085315e-04,  8.16879713e-03,  5.63030423e-03, -1.47057930e-03,\n",
      "        1.45749463e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58785044e-04,  1.09986183e-03, -8.05767756e-17,  6.76796280e-04,\n",
      "       -9.83393919e-04, -1.24251095e-03, -6.84053028e-05,  2.27191635e-03,\n",
      "       -3.42150398e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58794984e-04,  1.09986271e-03,  6.65324173e-18,  6.76800809e-04,\n",
      "       -9.83359301e-04, -1.24239498e-03,  5.90434327e-03, -1.47094619e-03,\n",
      "       -3.42130144e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18429133e-03, -1.39959293e-03, -1.77685632e-17,  6.76769413e-04,\n",
      "       -9.83293509e-04,  7.51352196e-04,  7.00291853e-03,  2.27181419e-03,\n",
      "        1.45777020e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18417872e-03,  1.09969101e-03,  3.11972894e-17,  6.76692701e-04,\n",
      "       -9.83179625e-04,  8.16938023e-03,  5.61724753e-03, -4.39474135e-04,\n",
      "       -3.42078998e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18432735e-03,  1.09983236e-03,  1.95843045e-17,  6.76782300e-04,\n",
      "        2.70591897e-03,  7.51354442e-04,  5.63089112e-03, -1.47089993e-03,\n",
      "       -3.42119946e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58680815e-04, -1.39954437e-03, -9.59001074e-17,  6.76723851e-04,\n",
      "       -9.83248935e-04,  8.16973758e-03,  3.07001403e-03, -1.47082033e-03,\n",
      "        1.45769485e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18422074e-03, -1.39949989e-03,  4.95807960e-18,  6.76716105e-04,\n",
      "       -9.83221002e-04,  8.16959899e-03,  5.63066445e-03, -1.47077159e-03,\n",
      "        1.45766546e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 7.46136339e-03, -1.39945404e-03, -6.96321717e-17,  6.76703771e-04,\n",
      "       -9.83188932e-04,  7.51282673e-04,  7.00253596e-03, -4.39454906e-04,\n",
      "       -1.01496547e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18418436e-03, -1.39945555e-03, -4.58381434e-17,  6.76696101e-04,\n",
      "        1.23892854e-03,  8.16941546e-03,  5.63059658e-03, -4.39474526e-04,\n",
      "       -3.42080480e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58750261e-04,  1.09981638e-03,  4.22048409e-18,  6.76772504e-04,\n",
      "        2.70588682e-03, -1.24234017e-03,  5.61753152e-03, -4.39509667e-04,\n",
      "       -3.42112889e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58611081e-04,  1.09967111e-03, -4.01979898e-17,  6.76679857e-04,\n",
      "        2.70559452e-03,  8.16932161e-03,  2.16052830e-03, -1.47072056e-03,\n",
      "       -1.01496244e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58791019e-04,  1.09986592e-03,  1.76901654e-17, -8.29449393e-04,\n",
      "       -9.83384263e-04,  7.51328005e-04,  1.39674430e-03,  2.27192722e-03,\n",
      "       -3.42147435e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 7.46152817e-03,  1.09969961e-03,  2.93599172e-17,  6.76694979e-04,\n",
      "        1.23895966e-03,  7.51161794e-04, -3.40728800e-03,  2.27162564e-03,\n",
      "        1.45766402e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18433377e-03, -1.39964079e-03,  5.00798032e-18,  6.76784444e-04,\n",
      "       -9.83328287e-04,  7.51354740e-04,  5.61755802e-03,  2.27186656e-03,\n",
      "        1.45780756e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18420882e-03, -1.39948230e-03, -5.43041787e-17, -8.29307744e-04,\n",
      "        4.02064382e-03,  8.16949146e-03,  4.56292105e-03, -1.47074853e-03,\n",
      "       -3.42087212e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 7.45919734e-03,  1.09934074e-03,  2.73209106e-17,  6.76477361e-04,\n",
      "       -9.82840899e-04,  8.42308749e-03,  5.61602211e-03, -1.47022161e-03,\n",
      "       -3.41963831e-04])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-1.18419649e-03,  1.09970663e-03, -4.23304862e-17, -8.29299899e-04,\n",
      "       -9.83197512e-04,  8.16947093e-03,  5.61727522e-03, -1.47073832e-03,\n",
      "        1.45763658e-03])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([ 9.58377487e-04, -1.39906148e-03, -2.40500109e-17,  6.76511118e-04,\n",
      "        4.01958860e-03,  8.16749507e-03,  5.61624446e-03,  2.27099235e-03,\n",
      "       -3.41981770e-04])\n",
      "INFO:shap:num_full_subsets = 3\n",
      "INFO:shap:phi = array([ 2.14303582e-03,  1.50612261e-03, -3.68898030e-03,  9.41238241e-03,\n",
      "       -1.32663752e-03, -1.73472348e-18])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00741716, 0.00878535])\n",
      "INFO:shap:num_full_subsets = 3\n",
      "INFO:shap:phi = array([ 6.50091107e-03, -1.50553053e-03,  3.68786382e-03,  9.40952170e-03,\n",
      "        1.21149786e-18,  0.00000000e+00])\n",
      "INFO:shap:num_full_subsets = 2\n",
      "INFO:shap:phi = array([-3.07574380e-20, -3.07574380e-20,  3.14785857e-03, -2.71163350e-03])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00336838, 0.00103149])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00941219, 0.00271118])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00941117, 0.00469398])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00268196, 0.00941202])\n",
      "INFO:shap:num_full_subsets = 2\n",
      "INFO:shap:phi = array([1.19916743e-18, 1.50620359e-03, 6.54705214e-19, 3.01765636e-03,\n",
      "       3.74286844e-03])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00741847, 0.0037426 ])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.0096686, 0.       ])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.        , 0.00268249])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00268217, 0.00741874])\n",
      "INFO:shap:num_full_subsets = 3\n",
      "INFO:shap:phi = array([ 2.14249995e-03, -5.47836163e-20, -1.14949596e-18,  9.41054776e-03,\n",
      "        3.36715579e-03,  2.71061565e-03,  1.79939195e-03])\n",
      "INFO:shap:num_full_subsets = 2\n",
      "INFO:shap:phi = array([ 0.00649384,  0.0024957 ,  0.02659642, -0.00270697])\n",
      "INFO:shap:num_full_subsets = 3\n",
      "INFO:shap:phi = array([ 1.03850115e-18,  2.49868272e-03,  3.68810237e-03,  9.41010591e-03,\n",
      "        1.33388308e-05, -2.52483593e-18,  1.79932592e-03])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00249891, 0.00500329, 0.00941093])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00941087, 0.00635627])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00150618, 0.00741885])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-2.42495354e-18,  2.49859422e-03, -1.52421857e-18, -5.32466627e-18,\n",
      "        2.78092662e-03,  9.40982804e-03, -9.86382514e-19,  3.99903374e-03])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00941093, 0.00902423])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.0094121, 0.0012889])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([-0.00268062,  0.00940894,  0.02175466])\n",
      "INFO:shap:num_full_subsets = 2\n",
      "INFO:shap:phi = array([3.38621897e-18, 3.43412424e-18, 7.67442247e-03, 2.68132908e-03,\n",
      "       6.72926879e-04])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00941138, 0.00470742])\n",
      "INFO:shap:num_full_subsets = 3\n",
      "INFO:shap:phi = array([ 1.06007642e-19,  2.68243160e-03,  3.97835774e-19, -9.91047966e-04,\n",
      "        2.71160176e-03,  0.00000000e+00])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.0060806, 0.0018   ])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00268204, 0.00941229])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00249964, 0.00338164])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.       , 0.0094126])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00864638, 0.00475341])\n",
      "INFO:shap:num_full_subsets = 4\n",
      "INFO:shap:phi = array([-2.14294447e-03,  6.17351754e-19, -2.56759770e-20,  2.22230503e-03,\n",
      "        7.41865267e-03,  4.70803369e-03,  1.03134513e-03,  3.46944695e-18])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00249926, 0.00941203])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00893238, 0.00150612])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00941227, 0.        ])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.00767104, 0.02280818])\n",
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:phi = array([0.0094125, 0.0024728])\n",
      "INFO:shap:num_full_subsets = 3\n",
      "INFO:shap:phi = array([-2.49792448e-03,  2.99888150e-18,  2.78040632e-03,  2.28069110e-02,\n",
      "        2.70990957e-03, -1.79881464e-03])\n"
     ]
    }
   ],
   "source": [
    "sample_num = 50\n",
    "max_round = 50\n",
    "ce_max_iter = 50\n",
    "ci_factor = 1.96  # 95% confidence interval factor\n",
    "n_proj = 10\n",
    "delta = 0.05\n",
    "counterfactual = 'DiCE'\n",
    "\n",
    "X_test_ext = X_test.copy()\n",
    "X_test_ext[target_name] = model.predict(X_test.values)\n",
    "\n",
    "if counterfactual is None:\n",
    "    df_baseline = X_test[X_test_ext[target_name] == 0]\n",
    "    df_explain = X_test[X_test_ext[target_name] == 1]\n",
    "\n",
    "    max_len = min(df_baseline.shape[0], df_explain.shape[0], sample_num)\n",
    "\n",
    "    df_baseline = df_baseline.sample(max_len)\n",
    "    df_explain = df_explain.sample(int(max_len))\n",
    "\n",
    "    X_baseline = df_baseline.values\n",
    "    y_baseline = model.predict_proba(X_baseline)\n",
    "    X_explain = df_explain.values\n",
    "    y_explain = model.predict_proba(X_explain)\n",
    "\n",
    "elif counterfactual == 'DCE':\n",
    "    indice = (X_test[X_test_ext[target_name]==1].sample(sample_num)).index\n",
    "    df_explain = X_test.loc[indice]\n",
    "    X_explain = df_explain.values\n",
    "    y_explain = model.predict_proba(X_explain)\n",
    "    y_target = torch.zeros(df_explain.shape[0])\n",
    "\n",
    "    explainer = dce.DistributionalCounterfactualExplainer(\n",
    "        model=model, \n",
    "        df_X=df_explain, \n",
    "        explain_columns=df_explain.columns,\n",
    "        y_target=y_target, \n",
    "        lr=1e-1, \n",
    "        n_proj=n_proj,\n",
    "        delta=0.05)\n",
    "\n",
    "    explainer.optimize(U_1=0.4, U_2=0.2, l=0.2, r=1, max_iter=ce_max_iter, tau=1e3)\n",
    "    df_baseline = pd.DataFrame(\n",
    "        explainer.best_X.detach().numpy(), \n",
    "        columns=explainer.explain_columns,\n",
    "        index=indice)\n",
    "    X_baseline = df_baseline.values\n",
    "    y_baseline = explainer.best_y.detach().numpy().flatten()\n",
    "    # y_baseline = y_target\n",
    "\n",
    "elif counterfactual == 'DiCE':\n",
    "    indice = (X_test[X_test_ext[target_name]==0].sample(sample_num)).index\n",
    "    df_explain = X_test.loc[indice]\n",
    "    X_explain = df_explain.values\n",
    "    y_explain = model.predict_proba(X_explain)\n",
    "    y_target = torch.zeros(df_explain.shape[0])\n",
    "\n",
    "    dice_model = dice_ml.Model(model=model, backend='sklearn')\n",
    "    dice_features = df_explain.columns.to_list()\n",
    "    dice_data = dice_ml.Data(\n",
    "        dataframe=X_test_ext.loc[indice], \n",
    "        continuous_features=dice_features, \n",
    "        outcome_name=target_name\n",
    "    )\n",
    "    explainer = dice_ml.Dice(dice_data, dice_model)\n",
    "    dice_results = explainer.generate_counterfactuals(\n",
    "        query_instances=df_explain,\n",
    "        features_to_vary=dice_features, \n",
    "        desired_class='opposite', \n",
    "        total_CFs=1\n",
    "    )\n",
    "    # Iterate through each result and append to the DataFrame\n",
    "    dice_df_list = []\n",
    "    for cf in dice_results.cf_examples_list:\n",
    "        # Convert to DataFrame and append\n",
    "        cf_df = cf.final_cfs_df\n",
    "        dice_df_list.append(cf_df)\n",
    "\n",
    "    df_baseline = pd.concat(dice_df_list).reset_index(drop=True).drop(target_name, axis=1)\n",
    "    X_baseline = df_baseline.values\n",
    "    y_baseline = pd.concat(dice_df_list).reset_index(drop=True)[target_name].values\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# from explainers.distances import WassersteinDivergence, SlicedWassersteinDivergence\n",
    "\n",
    "# _, mu_list = SlicedWassersteinDivergence(\n",
    "#     dim=X_explain.shape[1], n_proj=1000\n",
    "# ).distance(torch.FloatTensor(X_explain), torch.FloatTensor(X_baseline), delta)\n",
    "\n",
    "# matrix_mu = get_ot_plan(mu_list, method='max')\n",
    "\n",
    "ot_cost = ot.dist(X_explain, X_baseline)\n",
    "matrix_mu = ot.emd(\n",
    "    np.ones(X_explain.shape[0])/X_explain.shape[0], \n",
    "    np.ones(X_baseline.shape[0])/X_baseline.shape[0], ot_cost\n",
    ")\n",
    "\n",
    "# # ot_cost = ot.dist(y_explain.reshape(-1,1), y_baseline.reshape(-1,1))\n",
    "# # matrix_mu = ot.emd(\n",
    "# #     np.ones(y_explain.shape[0])/y_explain.shape[0], \n",
    "# #     np.ones(y_baseline.shape[0])/y_baseline.shape[0], ot_cost\n",
    "# # )\n",
    "\n",
    "shap_explainer = shap.KernelExplainer(model.predict_proba, X_baseline)\n",
    "jp_explainer = pshap.JointProbabilityExplainer(model)\n",
    "# jp_explainer = shap.KernelExplainer(model.predict_proba, X_train.sample(max_len))\n",
    "\n",
    "shap_values_baseline = shap_explainer.shap_values(X_explain)\n",
    "shap_values_jp = jp_explainer.shap_values(X_explain, X_baseline, joint_probs=matrix_mu)\n",
    "# shap_values_jp = jp_explainer.shap_values(X_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8102cf0845547a6b65cbf8d77b6ec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_pairs_list = [25, 50, 75, 100, 150, 200, 250, 300, 400]\n",
    "\n",
    "# Initialize interactive output display\n",
    "plt.ioff()\n",
    "out = widgets.Output()\n",
    "vbox = widgets.VBox([out])\n",
    "display(vbox)\n",
    "\n",
    "# Lists to store accuracies over iterations\n",
    "ot_list_bs = []\n",
    "ot_list_jp = []\n",
    "exp_list_bs = []\n",
    "exp_list_jp = []\n",
    "kl_list_bs = []\n",
    "kl_list_jp = []\n",
    "mmd_list_bs = []\n",
    "mmd_list_jp = []\n",
    "\n",
    "for t in range(max_round):\n",
    "\n",
    "    ot_start, _ = WassersteinDivergence().distance(\n",
    "        torch.FloatTensor(y_explain), \n",
    "        torch.FloatTensor(y_baseline),\n",
    "        delta=delta,\n",
    "        )\n",
    "    kl_start = kl_div(\n",
    "            y_explain, \n",
    "            y_baseline,\n",
    "        ).mean()\n",
    "    mmd_start = compute_mmd(\n",
    "            y_explain, \n",
    "            y_baseline,\n",
    "        )\n",
    "    exp_start = abs(y_explain.mean() - y_baseline.mean())\n",
    "    results = [{\n",
    "        'OT_bs': ot_start, 'OT_jp': ot_start,\n",
    "        'KL_bs': kl_start, 'KL_jp': kl_start,\n",
    "        'EXP_bs': exp_start, 'EXP_jp': exp_start,\n",
    "        'MMD_bs': mmd_start, 'MMD_jp': mmd_start,\n",
    "        }]\n",
    "    # results = []\n",
    "    \n",
    "    for num_pairs in num_pairs_list:\n",
    "        result = counterfactual_ability_performance_benchmarking(\n",
    "                model=model,\n",
    "                df_explain=df_explain,\n",
    "                df_baseline=df_baseline,\n",
    "                y_baseline=y_baseline,\n",
    "                shap_values_baseline=shap_values_baseline,\n",
    "                shap_values_jp=shap_values_jp,\n",
    "                num_pairs=num_pairs,\n",
    "                delta=delta,\n",
    "        )\n",
    "        results.append(result)\n",
    "\n",
    "    new_ot_bs = [result['OT_bs'] for result in results]\n",
    "    new_ot_jp = [result['OT_jp'] for result in results]\n",
    "\n",
    "    new_kl_bs = [result['KL_bs'] for result in results]\n",
    "    new_kl_jp = [result['KL_jp'] for result in results]\n",
    "\n",
    "    new_exp_bs = [result['EXP_bs'] for result in results]\n",
    "    new_exp_jp = [result['EXP_jp'] for result in results]\n",
    "\n",
    "    new_mmd_bs = [result['MMD_bs'] for result in results]\n",
    "    new_mmd_jp = [result['MMD_jp'] for result in results]\n",
    "\n",
    "    ot_list_bs.append(new_ot_bs)\n",
    "    ot_list_jp.append(new_ot_jp)\n",
    "\n",
    "    kl_list_bs.append(new_kl_bs)\n",
    "    kl_list_jp.append(new_kl_jp)\n",
    "\n",
    "    exp_list_bs.append(new_exp_bs)\n",
    "    exp_list_jp.append(new_exp_jp)\n",
    "\n",
    "    mmd_list_bs.append(new_mmd_bs)\n",
    "    mmd_list_jp.append(new_mmd_jp)\n",
    "\n",
    "    # Compute mean and confidence intervals for OT\n",
    "    ot_means_bs = np.mean(ot_list_bs, axis=0)\n",
    "    ot_means_jp = np.mean(ot_list_jp, axis=0)\n",
    "    ot_std_err_bs = stats.sem(ot_means_bs, axis=0)\n",
    "    ot_std_err_jp = stats.sem(ot_means_jp, axis=0)\n",
    "    ot_ci_bs = ot_std_err_bs * ci_factor / np.sqrt(t+1)\n",
    "    ot_ci_jp = ot_std_err_jp * ci_factor / np.sqrt(t+1)\n",
    "\n",
    "    # Compute mean and confidence intervals for KL\n",
    "    kl_means_bs = np.mean(kl_list_bs, axis=0)\n",
    "    kl_means_jp = np.mean(kl_list_jp, axis=0)\n",
    "    kl_std_err_bs = stats.sem(kl_means_bs, axis=0)\n",
    "    kl_std_err_jp = stats.sem(kl_means_jp, axis=0)\n",
    "    kl_ci_bs = kl_std_err_bs * ci_factor / np.sqrt(t+1)\n",
    "    kl_ci_jp = kl_std_err_jp * ci_factor / np.sqrt(t+1)\n",
    "\n",
    "    # Compute mean and confidence intervals for expectation diff\n",
    "    exp_means_bs = np.mean(exp_list_bs, axis=0)\n",
    "    exp_means_jp = np.mean(exp_list_jp, axis=0)\n",
    "    exp_std_err_bs = stats.sem(exp_means_bs, axis=0)\n",
    "    exp_std_err_jp = stats.sem(exp_means_jp, axis=0)\n",
    "    exp_ci_bs = exp_std_err_bs * ci_factor / np.sqrt(t+1)\n",
    "    exp_ci_jp = exp_std_err_jp * ci_factor / np.sqrt(t+1)\n",
    "\n",
    "    # Compute mean and confidence intervals for MMD\n",
    "    mmd_means_bs = np.mean(mmd_list_bs, axis=0)\n",
    "    mmd_means_jp = np.mean(mmd_list_jp, axis=0)\n",
    "    mmd_std_err_bs = stats.sem(mmd_means_bs, axis=0)\n",
    "    mmd_std_err_jp = stats.sem(mmd_means_jp, axis=0)\n",
    "    mmd_ci_bs = mmd_std_err_bs * ci_factor / np.sqrt(t+1)\n",
    "    mmd_ci_jp = mmd_std_err_jp * ci_factor / np.sqrt(t+1)\n",
    "\n",
    "    fig, axes = plt.subplots(1,4,figsize=(16, 3))\n",
    "    x_labels =  [0] + num_pairs_list\n",
    "\n",
    "    # Plotting code for OT Distance\n",
    "    axes[0].plot(x_labels, ot_means_bs, label='SHAP', marker='o')\n",
    "    axes[0].fill_between(x_labels, ot_means_bs - ot_ci_bs, ot_means_bs + ot_ci_bs, alpha=0.2)\n",
    "    axes[0].plot(x_labels, ot_means_jp, label='JP-SHAP', marker='o')\n",
    "    axes[0].fill_between(x_labels, ot_means_jp - ot_ci_jp, ot_means_jp + ot_ci_jp, alpha=0.2)\n",
    "    axes[0].set_xlabel('Number of Changes')\n",
    "    axes[0].set_ylabel('OT Distance')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plotting code for MMD Divergence\n",
    "    axes[1].plot(x_labels, mmd_means_bs, label='SHAP', marker='o')\n",
    "    axes[1].fill_between(x_labels, mmd_means_bs - mmd_ci_bs, mmd_means_bs + mmd_ci_bs, alpha=0.2)\n",
    "    axes[1].plot(x_labels, mmd_means_jp, label='JP-SHAP', marker='o')\n",
    "    axes[1].fill_between(x_labels, mmd_means_jp - mmd_ci_jp, mmd_means_jp + mmd_ci_jp, alpha=0.2)\n",
    "    axes[1].set_xlabel('Number of Changes')\n",
    "    axes[1].set_ylabel('MMD')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Plotting code for MMD Divergence\n",
    "    axes[2].plot(x_labels, exp_means_bs, label='SHAP', marker='o')\n",
    "    axes[2].fill_between(x_labels, exp_means_bs - exp_ci_bs, exp_means_bs + exp_ci_bs, alpha=0.2)\n",
    "    axes[2].plot(x_labels, exp_means_jp, label='JP-SHAP', marker='o')\n",
    "    axes[2].fill_between(x_labels, exp_means_jp - exp_ci_jp, exp_means_jp + exp_ci_jp, alpha=0.2)\n",
    "    axes[2].set_xlabel('Number of Changes')\n",
    "    axes[2].set_ylabel('Exp Diff')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    # Plotting code for KL Divergence\n",
    "    axes[3].plot(x_labels, kl_means_bs, label='SHAP', marker='o')\n",
    "    axes[3].fill_between(x_labels, kl_means_bs - kl_ci_bs, kl_means_bs + kl_ci_bs, alpha=0.2)\n",
    "    axes[3].plot(x_labels, kl_means_jp, label='JP-SHAP', marker='o')\n",
    "    axes[3].fill_between(x_labels, kl_means_jp - kl_ci_jp, kl_means_jp + kl_ci_jp, alpha=0.2)\n",
    "    axes[3].set_xlabel('Number of Changes')\n",
    "    axes[3].set_ylabel('KL')\n",
    "    axes[3].legend()\n",
    "    axes[3].grid(True)\n",
    "\n",
    "    # Adjust the spacing between the plots\n",
    "    fig.subplots_adjust(wspace=0.5)  # Increase the width space\n",
    "\n",
    "    with out:\n",
    "        clear_output(wait=True);\n",
    "        print(f'Round:{t}')\n",
    "        display(fig)\n",
    "\n",
    "    plt.close(fig)  # Close the figure to free memory and avoid unnecessary resource use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_bs = np.abs(shap_values_baseline) / np.abs(shap_values_baseline).sum()\n",
    "P_jp = np.abs(shap_values_jp) / np.abs(shap_values_jp).sum()\n",
    "\n",
    "num_pairs = 5\n",
    "\n",
    "# Flatten the array to make it easier to sample from\n",
    "flat_indices = np.random.choice(a=P_jp.size, size=num_pairs, p=P_jp.flatten(), replace=True)\n",
    "flat_indices = np.unique(flat_indices)\n",
    "\n",
    "# Convert flat indices back to 2D indices\n",
    "i_indices, j_indices = np.unravel_index(flat_indices, P_jp.shape)\n",
    "\n",
    "X_explain_current = X_explain.copy()\n",
    "\n",
    "# Set values at selected_pairs\n",
    "values_from_baseline = X_baseline[i_indices, j_indices]\n",
    "X_explain_current[i_indices, j_indices] = values_from_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.199, 0.   , 0.713, 0.   , 0.   , 0.   , 0.001, 0.975, 0.006,\n",
       "       0.   , 0.   , 0.34 , 0.003, 0.378, 0.   , 0.55 , 0.556, 0.001,\n",
       "       0.001, 0.389, 0.   , 0.101, 0.812, 0.   , 0.   , 0.002, 1.   ,\n",
       "       0.003, 0.606, 0.023, 0.91 , 0.   , 0.003, 0.   , 0.452, 0.999,\n",
       "       0.208, 0.   , 0.   , 0.139, 0.044, 0.038, 0.   , 0.001, 0.618,\n",
       "       0.   , 0.505, 0.87 , 0.998, 0.072], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_explain.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.019, 0.705, 0.006, 0.103, 0.024, 0.   , 0.   , 0.008, 0.   ,\n",
       "       0.001, 0.001, 0.012, 0.   , 0.002, 0.   , 0.843, 0.993, 0.   ,\n",
       "       0.023, 0.411, 0.083, 0.005, 0.019, 0.999, 0.   , 0.509, 0.096,\n",
       "       0.   , 0.016, 0.   , 0.509, 0.03 , 0.327, 0.   , 0.516, 0.   ,\n",
       "       0.   , 0.015, 0.048, 0.003, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.004, 0.028, 0.   , 0.   , 1.   ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_baseline.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure and axes\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "\n",
    "# Plot the first SHAP summary plot on the first axis\n",
    "plt.sca(axs[0])  # Set the current axis to the first subplot\n",
    "shap.summary_plot(shap_values_baseline, X_explain, feature_names=df_explain.columns, plot_type='violin', show=False)\n",
    "axs[0].set_title('Baseline Model')\n",
    "\n",
    "# Plot the second SHAP summary plot on the second axis\n",
    "plt.sca(axs[1])  # Set the current axis to the second subplot\n",
    "shap.summary_plot(shap_values_jp, X_explain, feature_names=df_explain.columns, plot_type='violin', show=False)\n",
    "axs[1].set_title('JP Model')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_X = df[df_X.columns].loc[indice].copy()\n",
    "counterfactual_X = pd.DataFrame(explainer.best_X.detach().numpy() * std[df_X.columns].values + mean[df_X.columns].values, columns=df_X.columns, index=indice)\n",
    "\n",
    "# dtype_dict = df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "# for k, v in dtype_dict.items():\n",
    "#     if k in counterfactual_X.columns:\n",
    "#         if v[:3] == 'int':\n",
    "#             counterfactual_X[k] = counterfactual_X[k].round().astype(v)\n",
    "#         else:\n",
    "#             counterfactual_X[k] = counterfactual_X[k].astype(v)\n",
    "\n",
    "factual_y = pd.DataFrame(y.detach().numpy(),columns=[target_name], index=factual_X.index)\n",
    "counterfactual_y = pd.DataFrame(explainer.y.detach().numpy(),columns=[target_name], index=factual_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, reverse the label encoding using the label_mappings\n",
    "for dft in [factual_X, counterfactual_X]:\n",
    "    for column, mapping in label_mappings.items():\n",
    "        if column in dft.columns:\n",
    "            # Invert the label mapping dictionary\n",
    "            inv_mapping = {v: k for k, v in mapping.items()}\n",
    "            # Map the encoded labels back to the original strings\n",
    "            dft[column] = dft[column].map(inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = factual_X\n",
    "counterfactual = counterfactual_X\n",
    "\n",
    "factual[target_name] = factual_y\n",
    "counterfactual[target_name] = counterfactual_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matrix_nu = explainer.wd.nu.detach().numpy()\n",
    "\n",
    "mu_avg = torch.zeros_like(explainer.swd.mu_list[0])\n",
    "for mu in explainer.swd.mu_list:\n",
    "    mu_avg += mu\n",
    "\n",
    "total_sum = mu_avg.sum()\n",
    "\n",
    "matrix_mu = mu_avg / total_sum\n",
    "\n",
    "# Determine the global minimum and maximum values across both matrices\n",
    "vmin = min(matrix_mu.min(), matrix_nu.min())\n",
    "vmax = max(matrix_mu.max(), matrix_nu.max())\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8))  # 1 row, 2 columns\n",
    "\n",
    "# First subplot for matrix_mu\n",
    "im_mu = axs[0].imshow(matrix_mu, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_title(\"Heatmap of $\\mu$\")\n",
    "\n",
    "# Second subplot for matrix_nu\n",
    "im_nu = axs[1].imshow(matrix_nu, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axs[1].set_title(\"Heatmap of $\\\\nu$\")\n",
    "\n",
    "# Create a colorbar for the whole figure\n",
    "fig.colorbar(im_mu, ax=axs, orientation='vertical')\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
